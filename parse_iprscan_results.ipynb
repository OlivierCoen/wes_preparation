{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from functools import partial"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = [\n",
    "    \"protein_accession\",\n",
    "    \"sequence_md5_digest\",\n",
    "    \"sequence_length\",\n",
    "    \"analysis\",\n",
    "    \"signature_accession\",\n",
    "    \"signature_description\",\n",
    "    \"start_location\",\n",
    "    \"stop_location\",\n",
    "    \"score\",\n",
    "    \"status\",\n",
    "    \"date\",\n",
    "    \"interpro_annotations_accession\",\n",
    "    \"interpro_annotations_description\",\n",
    "    \"go_annotation\",\n",
    "    \"pathway_annotation\"\n",
    "]"
   ],
   "id": "11b06a8db18814a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "file = \"/home/olivier/interproscan/output/Ahypochondriacus_315_v1.0.protein.fa.tsv\"\n",
    "df = pd.read_csv(file, sep=\"\\t\", header=None, names=columns)"
   ],
   "id": "8a2e0f68c76d538e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "b7b7fc8b108ff4f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys, json, ssl\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError\n",
    "from time import sleep\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_nb_entries(database: str):\n",
    "    BASE_URL = f\"https://www.ebi.ac.uk:443/interpro/api/entry/all/{database}/\"\n",
    "    req = request.Request(BASE_URL, headers={\"Accept\": \"application/json\"})\n",
    "    res = request.urlopen(req)\n",
    "    payload = json.loads(res.read().decode())\n",
    "    return payload[\"count\"]\n",
    "\n",
    "\n",
    "def get_entries(database: str):\n",
    "    \n",
    "    PAGE_SIZE = 200\n",
    "    BASE_URL = f\"https://www.ebi.ac.uk:443/interpro/api/entry/all/database/?page_size={PAGE_SIZE}\"\n",
    "    \n",
    "    entries = []\n",
    "  \n",
    "    #disable SSL verification to avoid config issues\n",
    "    context = ssl._create_unverified_context()\n",
    "    \n",
    "    next = BASE_URL\n",
    "    \n",
    "    total_nb_entries = get_nb_entries(database)\n",
    "    pbar = tqdm(total=total_nb_entries)\n",
    "    \n",
    "    attempts = 0\n",
    "    i = 0\n",
    "    while next:\n",
    "    \n",
    "        try:\n",
    "            req = request.Request(next, headers={\"Accept\": \"application/json\"})\n",
    "            res = request.urlopen(req, context=context)\n",
    "            # If the API times out due a long running query\n",
    "            if res.status == 408:\n",
    "                # wait just over a minute\n",
    "                sleep(61)\n",
    "                # then continue this loop with the same URL\n",
    "                continue\n",
    "            elif res.status == 204:\n",
    "                #no data so leave loop\n",
    "                break\n",
    "            payload = json.loads(res.read().decode())\n",
    "            next = payload[\"next\"]\n",
    "            attempts = 0\n",
    "            \n",
    "            entries += payload[\"results\"]\n",
    "        \n",
    "        except HTTPError as e:\n",
    "            if e.code == 408:\n",
    "                sleep(61)\n",
    "                continue\n",
    "            else:\n",
    "                # If there is a different HTTP error, it wil re-try 3 times before failing\n",
    "                if attempts < 3:\n",
    "                    attempts += 1\n",
    "                    sleep(61)\n",
    "                    continue\n",
    "                else:\n",
    "                    sys.stderr.write(\"LAST URL: \" + next)\n",
    "                    raise e\n",
    "          \n",
    "        # Don't overload the server, give it time before asking for more\n",
    "        if next:\n",
    "            sleep(1)\n",
    "        \n",
    "        i += 1\n",
    "        pbar.update(i * PAGE_SIZE)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    return entries"
   ],
   "id": "d917aa569aea46dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pfam_entries = get_entries(database=\"pfam\")\n",
    "panther_entries = get_entries(database=\"panther\")\n",
    "ncbifam_entries = get_entries(database=\"ncbifam\")\n",
    "cdd_entries = get_entries(database=\"cdd\")\n",
    "superfamily_entries = get_entries(database=\"ssf\")\n",
    "smart_entries = get_entries(database=\"smart\")\n",
    "prosite_profile_entries = get_entries(database=\"profile\")\n",
    "prosite_pattern_entries = get_entries(database=\"prosite\")\n"
   ],
   "id": "4fb051cf45e60c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.analysis.unique()",
   "id": "1744d4a1c148e650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_specific_entries(entries, keyword: str):\n",
    "    specific_entries = []\n",
    "    for entry in entries:\n",
    "        metadata = entry[\"metadata\"]\n",
    "        if keyword.lower() in metadata[\"name\"].lower():\n",
    "            specific_entries.append(metadata[\"accession\"])\n",
    "    return specific_entries"
   ],
   "id": "d47f7802ffd71c42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "keywords = [\n",
    "    \"integrase\",\n",
    "    \"reverse transcriptase\",\n",
    "    \"RNase H\",\n",
    "    \"transpos\",\n",
    "    \"ribosom\"\n",
    "]"
   ],
   "id": "e8486944f0b251a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "specific_entries = []\n",
    "for keyword in keywords:\n",
    "    specific_entries += get_specific_entries(entries, keyword)\n",
    "specific_entries = list(set(specific_entries))"
   ],
   "id": "5dd583dc8746d3f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask_antifam = (df.analysis == \"AntiFam\")\n",
    "mask_pfam = (df.analysis == \"Pfam\") & (df.signature_accession.isin(specific_entries))\n",
    "\n",
    "filtered_df = df[mask_antifam | mask_pfam]"
   ],
   "id": "51c3e7eaf14861d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def contains_keyword(string: str, keywords: list):\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in string.lower():\n",
    "            return True\n",
    "    return False"
   ],
   "id": "e91ad55a06c19809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "func = partial(contains_keyword, keywords=keywords)\n",
    "fdf = df[df.signature_description.apply(func)]\n",
    "with open(\"unwanted_proteins.txt\", \"w\") as fout:\n",
    "    fout.write(\"\\n\".join(fdf.protein_accession.unique().tolist()))\n",
    "len(fdf.protein_accession.unique())"
   ],
   "id": "3360a33328d57e3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b20a6697aaf919a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
